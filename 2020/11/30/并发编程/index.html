<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>并发编程 | xuesui的个人博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Java线程基础CPU核心数和线程数的关系 线程是CPU调度的最小单位，必须依赖于进程，且小于进程 进程是资源运行的最小单位（CPU也是一个进程） CPU有核心数的说法，以前CPU核心数和线程数是相同的，现在有很多是1：2的关系 CPU线程能支持很多进程运行（很多进程里还会自己开线程），原因是因为CPU有时间片轮转机制，CPU会为每个进程设置一个时间片，并放在一个队列中，用CPU的线程去处理这些时">
<meta property="og:type" content="article">
<meta property="og:title" content="并发编程">
<meta property="og:url" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/index.html">
<meta property="og:site_name" content="xuesui的个人博客">
<meta property="og:description" content="Java线程基础CPU核心数和线程数的关系 线程是CPU调度的最小单位，必须依赖于进程，且小于进程 进程是资源运行的最小单位（CPU也是一个进程） CPU有核心数的说法，以前CPU核心数和线程数是相同的，现在有很多是1：2的关系 CPU线程能支持很多进程运行（很多进程里还会自己开线程），原因是因为CPU有时间片轮转机制，CPU会为每个进程设置一个时间片，并放在一个队列中，用CPU的线程去处理这些时">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/ThreadLocal%E5%AE%9E%E7%8E%B01.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/ThreadLocal%E5%AE%9E%E7%8E%B02.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CAS%E5%8E%9F%E7%90%86.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/state.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%8F%AF%E9%87%8D%E5%86%99%E7%9A%84%E6%96%B9%E6%B3%95.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CLH%E9%98%9F%E5%88%97%E9%94%811.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CLH%E9%98%9F%E5%88%97%E9%94%812.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CLH%E9%98%9F%E5%88%97%E9%94%813.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CLH%E9%98%9F%E5%88%97%E9%94%814.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JMM1.png">
<meta property="og:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JMM2.png">
<meta property="article:published_time" content="2020-11-30T10:06:57.170Z">
<meta property="article:modified_time" content="2020-12-01T11:23:46.815Z">
<meta property="article:author" content="xuesui">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.png">
  
    <link rel="alternate" href="/atom.xml" title="xuesui的个人博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">xuesui的个人博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">xuesui</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-并发编程" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/" class="article-date">
  <time datetime="2020-11-30T10:06:57.170Z" itemprop="datePublished">2020-11-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      并发编程
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Java线程基础"><a href="#Java线程基础" class="headerlink" title="Java线程基础"></a>Java线程基础</h1><h2 id="CPU核心数和线程数的关系"><a href="#CPU核心数和线程数的关系" class="headerlink" title="CPU核心数和线程数的关系"></a>CPU核心数和线程数的关系</h2><ul>
<li>线程是CPU调度的最小单位，必须依赖于进程，且小于进程</li>
<li>进程是资源运行的最小单位（CPU也是一个进程）</li>
<li>CPU有核心数的说法，以前CPU核心数和线程数是相同的，现在有很多是1：2的关系</li>
<li>CPU线程能支持很多进程运行（很多进程里还会自己开线程），原因是因为CPU有时间片轮转机制，CPU会为每个进程设置一个时间片，并放在一个队列中，用CPU的线程去处理这些时间片，并且在时间片的时间运行完之后就立刻进行切换（切换时间片成为上下文切换，也会消耗CPU时间，一次5ms），如果有进程提前运行结束，或者阻塞，时间片也会提前结束，时间片最佳的分配时间是100ms，小了会消耗大量时间进行上下文切换，多了用户体验不佳</li>
</ul>
<h2 id="并行和并发"><a href="#并行和并发" class="headerlink" title="并行和并发"></a>并行和并发</h2><p>​    我们举个例子,如果有条高速公路A上面并排有8条车道,那么最大的<strong><em>并行</em></strong>车辆就是8辆此条高速公路A同时并排行走的车辆小于等于8辆的时候,车辆就可以并行运行。CPU也是这个原理,一个CPU相当于一个高速公路A,核心数或者线程数就相当于并排可以通行的车道;而多个CPU就相当于并排有多条高速公路,而每个高速公路并排有多个车道。</p>
<p>​    当谈论<strong><em>并发</em></strong>的时候一定要加个单位时间,也就是说单位时间内并发量是多少?离开了单位时间其实是没有意义的。</p>
<p>​    俗话说,一心不能二用,这对计算机也一样,原则上一个CPU只能分配给一个进程,以便运行这个进程。我们通常使用的计算机中只有一个CPU,也就是说只有一颗心,要让它一心多用同时运行多个进程,就必须使用并发技术。实现并发技术相当复杂,最容易理解的是“时间片轮转进程调度算法”。</p>
<p>​    综合来说：</p>
<ul>
<li><p>并发:指应用能够交替执行不同的任务,比如单CPU核心下执行多线程并非是同时执行多个任务,如果你开两个线程执行,就是在你几乎不可能察觉到的速度不断去切换这两个任务,已达到”同时执行效果”,其实并不是的,只是计算机的速度太快,我们无法察觉到而已</p>
</li>
<li><p>并行:指应用能够同时执行不同的任务,例:吃饭的时候可以边吃饭边打电话,这两件事情可以同时执行</p>
</li>
<li><p>两者区别:一个是交替执行,一个是同时执行</p>
</li>
</ul>
<h2 id="线程的启动和中止"><a href="#线程的启动和中止" class="headerlink" title="线程的启动和中止"></a>线程的启动和中止</h2><ul>
<li><p>启动：线程的启动只有两种方式</p>
<ul>
<li>继承Thread，并且调用start方法</li>
<li>实现Runnable接口，通过Thread启动</li>
</ul>
<p>但是还有一种能够获取回调的线程，就是FutureTask,他是实现Runnable接口的，有两种构造方法，传入Runnable或者传入Callable，调用get方法可以获取回调的值。</p>
</li>
<li><p>中止</p>
<ul>
<li>自然中止：run方法执行完毕，或者异常中止</li>
<li>手动中止：<ul>
<li>不安全操作：暂停、恢复和停止操作对应在线程Thread的API就是<strong>suspend()、resume()和stop()</strong>，但是都已经弃用，因为他们在结束了线程之后并不会释放资源，有很多问题。</li>
<li>安全操作：使用interrupt方法，这个方法只是把中断位设置为true，并不会暴力结束线程，调用isInterrupt方法可以获取中断位，调用Thread.Interrupted方法会返回中断位，并且重置中断位，处于阻塞的线程（在调用wait、join、sleep方法后）在调用此方法后会抛出一个异常</li>
</ul>
</li>
</ul>
</li>
<li><p>yield方法让当前线程让出CPU占用权，join方法可以让两个并发的线程顺序执行</p>
</li>
</ul>
<h2 id="锁用法"><a href="#锁用法" class="headerlink" title="锁用法"></a>锁用法</h2><ul>
<li><p>分类</p>
<ul>
<li>类锁</li>
<li>对象锁</li>
</ul>
</li>
<li><p>synchronized 以及ReentrantLock都是可重入锁，前者是非公平锁，后者可以在构造函数里设置为公平锁</p>
</li>
<li><p>wait与notify/notifyAll：</p>
<ul>
<li><p>等待唤醒机制：<br>  wait(); 等待/冻结 ：可以将线程冻结，释放CPU执行资格，释放CPU执行权，并把此线程临时存储到线程池</p>
<p>　　notify(); 唤醒线程池里面 任意一个线程，没有顺序<br>　　 notifyAll(); 唤醒线程池里面，全部的线程</p>
</li>
<li><p>使用等待唤醒注意事项：<br>1.使用来wait();冻结，就必须要被其他方notify();，否则一直wait()冻结，所以等待与唤醒是配合一起使用的<br>2.wait();  notify();  notifyAll(); 等方法必须被synchronized(锁) {包裹起来}，意思就是：wait();  notify();  notifyAll();  必须要有同步锁🔒，否则毫无意义<br>3.wait();  notify();  notifyAll(); 等方法必须持有同一把锁🔒，因为：lockA.wait();  只能使用 lockA.notify(); / lockA.notifyAll(); , 它们是使用同一把锁🔒的</p>
</li>
</ul>
</li>
</ul>
<h2 id="线程状态"><a href="#线程状态" class="headerlink" title="线程状态"></a>线程状态</h2><p>Java中线程的状态分为6种：</p>
<ol>
<li><p>初始(NEW)：新创建了一个线程对象，但还没有调用start()方法。</p>
</li>
<li><p>运行(RUNNABLE)：Java线程中将就绪（ready）和运行中（running）两种状态笼统的称为“运行”。</p>
<p>线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取CPU的使用权，此时处于就绪状态（ready）。就绪状态的线程在获得CPU时间片后变为运行中状态（running）。</p>
</li>
<li><p>阻塞(BLOCKED)：表示线程阻塞于锁。</p>
</li>
<li><p>等待(WAITING)：进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断）</p>
</li>
<li><p>超时等待(TIMED_WAITING)：该状态不同于WAITING，它可以在指定的时间后自行返回。</p>
</li>
<li><p>终止(TERMINATED)：表示该线程已经执行完毕。</p>
</li>
</ol>
<p>状态之间的变迁如下图所示：</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.png" class title="线程状态">

<h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><p>​    是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。</p>
<p>同时，死锁还有几个要求：</p>
<p>1、争夺资源的顺序不对，如果争夺资源的顺序是一样的，也不会产生死锁。</p>
<p>2、争夺者拿到资源不放手。</p>
<p>两种解决方式：</p>
<p>1、 内部通过顺序比较，确定拿锁的顺序。</p>
<p>2、采用尝试拿锁的机制。</p>
<h1 id="ThreadLocal辨析"><a href="#ThreadLocal辨析" class="headerlink" title="ThreadLocal辨析"></a>ThreadLocal辨析</h1><h2 id="与Synchonized的比较"><a href="#与Synchonized的比较" class="headerlink" title="与Synchonized的比较"></a>与Synchonized的比较</h2><p>​    ThreadLocal和Synchonized都用于解决多线程并发訪问。可是ThreadLocal与synchronized有本质的差别。synchronized是利用锁的机制，使变量或代码块在某一时该仅仅能被一个线程訪问。而ThreadLocal为每个线程都提供了变量的副本，使得每个线程在某一时间訪问到的并非同一个对象，这样就隔离了多个线程对数据的数据共享。</p>
<h2 id="ThreadLocal的使用"><a href="#ThreadLocal的使用" class="headerlink" title="ThreadLocal的使用"></a>ThreadLocal的使用</h2><p>ThreadLocal类接口很简单，只有4个方法，我们先来了解一下：</p>
<ul>
<li><p>void set(Object value) </p>
<p>设置当前线程的线程局部变量的值。</p>
</li>
<li><p>public Object get() </p>
<p>该方法返回当前线程所对应的线程局部变量。</p>
</li>
<li><p>public void remove() </p>
<p>将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。</p>
</li>
<li><p>protected Object initialValue() </p>
<p>返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。</p>
</li>
<li><p>public final static ThreadLocal<String> RESOURCE = new ThreadLocal<String>();</String></String></p>
<p>RESOURCE代表一个能够存放String类型的ThreadLocal对象。此时不论什么一个线程能够并发访问这个变量，对它进行写入、读取操作，都是线程安全的。</p>
</li>
</ul>
<h2 id="实现解析"><a href="#实现解析" class="headerlink" title="实现解析"></a>实现解析</h2><img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/ThreadLocal%E5%AE%9E%E7%8E%B01.png" class title="ThreadLocal实现1">

<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/ThreadLocal%E5%AE%9E%E7%8E%B02.png" class title="ThreadLocal实现2">

<ul>
<li><p>set方法：</p>
<p>通过getMap方法获取当前线程的ThreadLocalMap（实际就是Thread中的一个静态变量，初始化为null），向Entry数组中添加一个Entry</p>
</li>
<li><p>get方法：获取当前线程的ThreadLocalMap，如果为空，就返回ThreadLocal创建时的初始值，不为空，就获取当前线程这个ThreadLocal的value</p>
</li>
</ul>
<h1 id="CAS基本原理"><a href="#CAS基本原理" class="headerlink" title="CAS基本原理"></a>CAS基本原理</h1><h2 id="什么是原子操作？如何实现原子操作？"><a href="#什么是原子操作？如何实现原子操作？" class="headerlink" title="什么是原子操作？如何实现原子操作？"></a>什么是原子操作？如何实现原子操作？</h2><p>​    假定有两个操作A和B(A和B可能都很复杂)，如果从执行A的线程来看，当另一个线程执行B时，要么将B全部执行完，要么完全不执行B，那么A和B对彼此来说是原子的。</p>
<p>​    实现原子操作可以使用锁，锁机制，满足基本的需求是没有问题的了，但是有的时候我们的需求并非这么简单，我们需要更有效，更加灵活的机制，synchronized关键字是基于阻塞的锁机制，也就是说当一个线程拥有锁的时候，访问同一资源的其它线程需要等待，直到该线程释放锁，</p>
<p>​    这里会有些问题：首先，如果被阻塞的线程优先级很高很重要怎么办？其次，如果获得锁的线程一直不释放锁怎么办？（这种情况是非常糟糕的）。还有一种情况，如果有大量的线程来竞争资源，那CPU将会花费大量的时间和资源来处理这些竞争，同时，还有可能出现一些例如死锁之类的情况，最后，其实锁机制是一种比较粗糙，粒度比较大的机制，相对于像计数器这样的需求有点儿过于笨重。</p>
<p>​    实现原子操作还可以使用当前的处理器基本都支持CAS()的指令，只不过每个厂家所实现的算法并不一样，每一个CAS操作过程都包含三个运算符：一个内存地址V，一个期望的值A和一个新值B，操作的时候如果这个地址上存放的值等于这个期望的值A，则将地址上的值赋为新值B，否则不做任何操作。</p>
<p>​    CAS的基本思路就是，如果这个地址上的值和期望的值相等，则给其赋予新值，否则不做任何事儿，但是要返回原值是多少。循环CAS就是在一个循环里不断的做cas操作，直到成功为止。</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CAS%E5%8E%9F%E7%90%86.png" class title="CAS原理">

<h2 id="CAS实现原子操作的三大问题"><a href="#CAS实现原子操作的三大问题" class="headerlink" title="CAS实现原子操作的三大问题"></a>CAS实现原子操作的三大问题</h2><h3 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h3><p>​    因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。</p>
<p>​    ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。举个通俗点的例子，你倒了一杯水放桌子上，干了点别的事，然后同事把你水喝了又给你重新倒了一杯水，你回来看水还在，拿起来就喝，如果你不管水中间被人喝过，只关心水还在，这就是ABA问题。</p>
<p>​    如果你是一个讲卫生讲文明的小伙子，不但关心水在不在，还要在你离开的时候水被人动过没有，因为你是程序员，所以就想起了放了张纸在旁边，写上初始值0，别人喝水前麻烦先做个累加才能喝水。</p>
<h3 id="循环时间长开销大"><a href="#循环时间长开销大" class="headerlink" title="循环时间长开销大"></a>循环时间长开销大</h3><p>自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。</p>
<h3 id="只能保证一个共享变量的原子操作"><a href="#只能保证一个共享变量的原子操作" class="headerlink" title="只能保证一个共享变量的原子操作"></a>只能保证一个共享变量的原子操作</h3><p>​    当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。</p>
<p>​    还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。</p>
<h2 id="Jdk中相关原子操作类的使用"><a href="#Jdk中相关原子操作类的使用" class="headerlink" title="Jdk中相关原子操作类的使用"></a>Jdk中相关原子操作类的使用</h2><h3 id="AtomicInteger"><a href="#AtomicInteger" class="headerlink" title="AtomicInteger"></a>AtomicInteger</h3><ul>
<li><p>int addAndGet（int delta）：以原子方式将输入的数值与实例中的值（AtomicInteger里的value）相加，并返回结果。</p>
</li>
<li><p>boolean compareAndSet（int expect，int update）：如果输入的数值等于预期值，则以原子方式将该值设置为输入的值。</p>
</li>
<li><p>int getAndIncrement()：以原子方式将当前值加1，注意，这里返回的是自增前的值。</p>
</li>
<li><p>int getAndSet（int newValue）：以原子方式设置为newValue的值，并返回旧值。</p>
</li>
</ul>
<h3 id="AtomicIntegerArray"><a href="#AtomicIntegerArray" class="headerlink" title="AtomicIntegerArray"></a>AtomicIntegerArray</h3><p>主要是提供原子的方式更新数组里的整型，其常用方法如下。</p>
<p>•int addAndGet（int i，int delta）：以原子方式将输入值与数组中索引i的元素相加。</p>
<p>•boolean compareAndSet（int i，int expect，int update）：如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值。</p>
<p>​    需要注意的是，数组value通过构造方法传递进去，然后AtomicIntegerArray会将当前数组复制一份，所以当AtomicIntegerArray对内部的数组元素进行修改时，不会影响传入的数组。</p>
<h3 id="更新引用类型"><a href="#更新引用类型" class="headerlink" title="更新引用类型"></a>更新引用类型</h3><p>​    原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。</p>
<h4 id="AtomicReference"><a href="#AtomicReference" class="headerlink" title="AtomicReference"></a>AtomicReference</h4><p>原子更新引用类型。</p>
<h4 id="AtomicStampedReference"><a href="#AtomicStampedReference" class="headerlink" title="AtomicStampedReference"></a>AtomicStampedReference</h4><p>​    利用版本戳的形式记录了每次改变以后的版本号，这样的话就不会存在ABA问题了。这就是AtomicStampedReference的解决方案。AtomicMarkableReference跟AtomicStampedReference差不多， AtomicStampedReference是使用pair的int stamp作为计数器使用，AtomicMarkableReference的pair使用的是boolean mark。 还是那个水的例子，AtomicStampedReference可能关心的是动过几次，AtomicMarkableReference关心的是有没有被人动过，方法都比较简单。</p>
<h4 id="AtomicMarkableReference"><a href="#AtomicMarkableReference" class="headerlink" title="AtomicMarkableReference"></a>AtomicMarkableReference</h4><p>​    原子更新带有标记位的引用类型。可以原子更新一个布尔类型的标记位和引用类型。构造方法是AtomicMarkableReference（V initialRef，booleaninitialMark）。</p>
<h1 id="阻塞队列和线程池原理"><a href="#阻塞队列和线程池原理" class="headerlink" title="阻塞队列和线程池原理"></a>阻塞队列和线程池原理</h1><h2 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h2><h3 id="什么是阻塞队列"><a href="#什么是阻塞队列" class="headerlink" title="什么是阻塞队列"></a>什么是阻塞队列</h3><p>1）支持阻塞的插入方法：意思是当队列满时，队列会阻塞插入元素的线程，直到队列不满。</p>
<p>2）支持阻塞的移除方法：意思是在队列为空时，获取元素的线程会等待队列变为非空。</p>
<p>​    在并发编程中使用<strong><em>生产者和消费者模式</em></strong>能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序整体处理数据的速度。</p>
<p>​    在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。</p>
<p>​    为了解决这种生产消费能力不均衡的问题，便有了生产者和消费者模式。生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过阻塞队列来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。</p>
<p>​    阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97.png" class title="阻塞队列"> 

<ul>
<li><p>抛出异常：当队列满时，如果再往队列里插入元素，会抛出IllegalStateException（”Queuefull”）异常。当队列空时，从队列里获取元素会抛出NoSuchElementException异常。</p>
</li>
<li><p>返回特殊值：当往队列插入元素时，会返回元素是否插入成功，成功返回true。如果是移除方法，则是从队列里取出一个元素，如果没有则返回null。</p>
</li>
<li><p>一直阻塞：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到队列可用或者响应中断退出。当队列空时，如果消费者线程从队列里take元素，队列会阻塞住消费者线程，直到队列不为空。</p>
</li>
<li><p>超时退出：当阻塞队列满时，如果生产者线程往队列里插入元素，队列会阻塞生产者线程一段时间，如果超过了指定的时间，生产者线程就会退出。</p>
</li>
</ul>
<h3 id="常用阻塞队列"><a href="#常用阻塞队列" class="headerlink" title="常用阻塞队列"></a>常用阻塞队列</h3><ul>
<li><p>ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。</p>
</li>
<li><p>LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。</p>
</li>
<li><p>PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。</p>
</li>
<li><p>DelayQueue：一个使用优先级队列实现的无界阻塞队列。</p>
</li>
<li><p>SynchronousQueue：一个不存储元素的阻塞队列。</p>
</li>
<li><p>LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。</p>
</li>
<li><p>LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。</p>
</li>
</ul>
<p>以上的阻塞队列都实现了BlockingQueue接口，也都是线程安全的。</p>
<h4 id="有界无界？"><a href="#有界无界？" class="headerlink" title="有界无界？"></a>有界无界？</h4><p>​    有限队列就是长度有限，满了以后生产者会阻塞，无界队列就是里面能放无数的东西而不会因为队列长度限制被阻塞，当然空间限制来源于系统资源的限制，如果处理不及时，导致队列越来越大越来越大，超出一定的限制致使内存超限，操作系统或者JVM帮你解决烦恼，直接把你 OOM kill 省事了。</p>
<p>​    无界也会阻塞，为何？因为阻塞不仅仅体现在生产者放入元素时会阻塞，消费者拿取元素时，如果没有元素，同样也会阻塞。</p>
<h4 id="ArrayBlockingQueue"><a href="#ArrayBlockingQueue" class="headerlink" title="ArrayBlockingQueue"></a>ArrayBlockingQueue</h4><p>​    是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证线程公平的访问队列，所谓公平访问队列是指阻塞的线程，可以按照阻塞的先后顺序访问队列，即先阻塞线程先访问队列。非公平性是对先等待的线程是非公平的，当队列可用时，阻塞的线程都可以争夺访问队列的资格，有可能先阻塞的线程最后才访问队列。初始化时有参数可以设置</p>
<h4 id="LinkedBlockingQueue"><a href="#LinkedBlockingQueue" class="headerlink" title="LinkedBlockingQueue"></a>LinkedBlockingQueue</h4><p>是一个用链表实现的有界阻塞队列。此队列的默认和最大长度为Integer.MAX_VALUE。此队列按照先进先出的原则对元素进行排序。</p>
<h4 id="Array实现和Linked实现的区别"><a href="#Array实现和Linked实现的区别" class="headerlink" title="Array实现和Linked实现的区别"></a>Array实现和Linked实现的区别</h4><ol>
<li><p>队列中锁的实现不同</p>
<p>ArrayBlockingQueue实现的队列中的锁是没有分离的，即生产和消费用的是同一个锁；</p>
<p>LinkedBlockingQueue实现的队列中的锁是分离的，即生产用的是putLock，消费是takeLock</p>
</li>
<li><p>在生产或消费时操作不同</p>
<p>ArrayBlockingQueue实现的队列中在生产和消费的时候，是直接将枚举对象插入或移除的；</p>
<p>LinkedBlockingQueue实现的队列中在生产和消费的时候，需要把枚举对象转换为Node<E>进行插入或移除，会影响性能</E></p>
</li>
<li><p>队列大小初始化方式不同</p>
<p>ArrayBlockingQueue实现的队列中必须指定队列的大小；</p>
<p>LinkedBlockingQueue实现的队列中可以不指定队列的大小，但是默认是Integer.MAX_VALUE</p>
</li>
</ol>
<h4 id="PriorityBlockingQueue"><a href="#PriorityBlockingQueue" class="headerlink" title="PriorityBlockingQueue"></a>PriorityBlockingQueue</h4><p>​    PriorityBlockingQueue是一个支持优先级的无界阻塞队列。默认情况下元素采取自然顺序升序排列。也可以自定义类实现compareTo()方法来指定元素排序规则，或者初始化PriorityBlockingQueue时，指定构造参数Comparator来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。</p>
<h4 id="DelayQueue"><a href="#DelayQueue" class="headerlink" title="DelayQueue"></a>DelayQueue</h4><p>​    是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。</p>
<p>​    DelayQueue非常有用，可以将DelayQueue运用在以下应用场景。</p>
<p>​    缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。</p>
<h4 id="SynchronousQueue"><a href="#SynchronousQueue" class="headerlink" title="SynchronousQueue"></a>SynchronousQueue</h4><p>​    是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。SynchronousQueue可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合传递性场景。SynchronousQueue的吞吐量高于LinkedBlockingQueue和ArrayBlockingQueue。</p>
<h4 id="LinkedTransferQueue"><a href="#LinkedTransferQueue" class="headerlink" title="LinkedTransferQueue"></a>LinkedTransferQueue</h4><p>多了tryTransfer和transfer方法，</p>
<p>（1）transfer方法</p>
<p>如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。</p>
<p>（2）tryTransfer方法</p>
<p>tryTransfer方法是用来试探生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回，而transfer方法是必须等到消费者消费了才返回。</p>
<h4 id="LinkedBlockingDeque"><a href="#LinkedBlockingDeque" class="headerlink" title="LinkedBlockingDeque"></a>LinkedBlockingDeque</h4><p>​    LinkedBlockingDeque是一个由链表结构组成的双向阻塞队列。所谓双向队列指的是可以从队列的两端插入和移出元素。双向队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。</p>
<p>​    多了addFirst、addLast、offerFirst、offerLast、peekFirst和peekLast等方法，以First单词结尾的方法，表示插入、获取（peek）或移除双端队列的第一个元素。以Last单词结尾的方法，表示插入、获取或移除双端队列的最后一个元素。另外，插入方法add等同于addLast，移除方法remove等效于removeFirst。但是take方法却等同于takeFirst，不知道是不是JDK的bug，使用时还是用带有First和Last后缀的方法更清楚。在初始化LinkedBlockingDeque时可以设置容量防止其过度膨胀。另外，双向阻塞队列可以运用在“工作窃取”模式中。</p>
<h2 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h2><h3 id="为什么要用线程池？"><a href="#为什么要用线程池？" class="headerlink" title="为什么要用线程池？"></a>为什么要用线程池？</h3><p>​    Java中的线程池是运用场景最多的并发框架，几乎所有需要异步或并发执行任务的程序都可以使用线程池。在开发过程中，合理地使用线程池能够带来3个好处。</p>
<p>​    第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</p>
<p>​    第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。假设一个服务器完成一项任务所需时间为：T1 创建线程时间，T2 在线程中执行任务的时间，T3 销毁线程时间。  如果：T1 + T3 远大于 T2，则可以采用线程池，以提高服务器性能。线程池技术正是关注如何缩短或调整T1,T3时间的技术，从而提高服务器程序性能的。它把T1，T3分别安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在服务器程序处理客户请求时，不会有T1，T3的开销了。</p>
<p>​    第三：提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。</p>
<h3 id="ThreadPoolExecutor-的类关系"><a href="#ThreadPoolExecutor-的类关系" class="headerlink" title="ThreadPoolExecutor 的类关系"></a>ThreadPoolExecutor 的类关系</h3><p>​    Executor是一个接口，它是Executor框架的基础，它将任务的提交与任务的执行分离开来。</p>
<p>​    ExecutorService接口继承了Executor，在其上做了一些shutdown()、submit()的扩展，可以说是真正的线程池接口；</p>
<p>​    AbstractExecutorService抽象类实现了ExecutorService接口中的大部分方法；</p>
<p>​    ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务。</p>
<p>​    ScheduledExecutorService接口继承了ExecutorService接口，提供了带”周期执行”功能ExecutorService；</p>
<p>​    ScheduledThreadPoolExecutor是一个实现类，可以在给定的延迟后运行命令，或者定期执行命令。ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。</p>
<h3 id="线程池的创建各个参数含义"><a href="#线程池的创建各个参数含义" class="headerlink" title="线程池的创建各个参数含义"></a>线程池的创建各个参数含义</h3><p>​    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler)</Runnable></p>
<h4 id="corePoolSize"><a href="#corePoolSize" class="headerlink" title="corePoolSize"></a>corePoolSize</h4><p>​    线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；</p>
<p>​    如果当前线程数为corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；</p>
<p>​    如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。</p>
<h4 id="maximumPoolSize"><a href="#maximumPoolSize" class="headerlink" title="maximumPoolSize"></a>maximumPoolSize</h4><p>​    线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSize</p>
<h4 id="keepAliveTime"><a href="#keepAliveTime" class="headerlink" title="keepAliveTime"></a>keepAliveTime</h4><p>线程空闲时的存活时间，即当线程没有任务执行时，继续存活的时间。默认情况下，该参数只在线程数大于corePoolSize时才有用</p>
<h4 id="TimeUnit"><a href="#TimeUnit" class="headerlink" title="TimeUnit"></a>TimeUnit</h4><p>keepAliveTime的时间单位</p>
<h4 id="workQueue"><a href="#workQueue" class="headerlink" title="workQueue"></a>workQueue</h4><p>​    workQueue必须是BlockingQueue阻塞队列。当线程池中的线程数超过它的corePoolSize的时候，线程会进入阻塞队列进行阻塞等待。通过workQueue，线程池实现了阻塞功能。</p>
<p>​    一般来说，我们应该尽量使用有界队列，因为使用无界队列作为工作队列会对线程池带来如下影响。</p>
<p>​    1）当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中的线程数不会超过corePoolSize。</p>
<p>​    2）由于1，使用无界队列时maximumPoolSize将是一个无效参数。</p>
<p>​    3）由于1和2，使用无界队列时keepAliveTime将是一个无效参数。</p>
<p>​    4）更重要的，使用无界queue可能会耗尽系统资源，有界队列则有助于防止资源耗尽，同时即使使用有界队列，也要尽量控制队列的大小在一个合适的范围。</p>
<h4 id="threadFactory"><a href="#threadFactory" class="headerlink" title="threadFactory"></a>threadFactory</h4><p>​    创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名，当然还可以更加自由的对线程做更多的设置，比如设置所有的线程为守护线程。</p>
<p>​    Executors静态工厂里默认的threadFactory，线程的命名规则是“pool-数字-thread-数字”。</p>
<h4 id="RejectedExecutionHandler"><a href="#RejectedExecutionHandler" class="headerlink" title="RejectedExecutionHandler"></a>RejectedExecutionHandler</h4><p>​    线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略：</p>
<p>（1）AbortPolicy：直接抛出异常，默认策略；</p>
<p>（2）CallerRunsPolicy：用调用者所在的线程来执行任务；</p>
<p>（3）DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；</p>
<p>（4）DiscardPolicy：直接丢弃任务；</p>
<p>当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。</p>
<h3 id="线程池的工作机制"><a href="#线程池的工作机制" class="headerlink" title="线程池的工作机制"></a>线程池的工作机制</h3><p>1）如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。</p>
<p>2）如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。</p>
<p>3）如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务。</p>
<p>4）如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。</p>
<h3 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h3><p>​    execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。</p>
<p>​    submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</p>
<h3 id="关闭线程池"><a href="#关闭线程池" class="headerlink" title="关闭线程池"></a>关闭线程池</h3><p>​    可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法终止。但是它们存在一定的区别，shutdownNow首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断<strong><em>所有没有正在执行任务的线程</em></strong>。</p>
<p>​    只要调用了这两个关闭方法中的任意一个，isShutdown方法就会返回true。当所有的任务都已关闭后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true。至于应该调用哪一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow方法。</p>
<h3 id="合理地配置线程池"><a href="#合理地配置线程池" class="headerlink" title="合理地配置线程池"></a>合理地配置线程池</h3><p>​    要想合理地配置线程池，就必须首先分析任务特性</p>
<p>​    要想合理地配置线程池，就必须首先分析任务特性，可以从以下几个角度来分析。</p>
<ul>
<li><p>任务的性质：CPU密集型任务、IO密集型任务和混合型任务。</p>
</li>
<li><p>任务的优先级：高、中和低。</p>
</li>
<li><p>任务的执行时间：长、中和短。</p>
</li>
<li><p>任务的依赖性：是否依赖其他系统资源，如数据库连接。</p>
</li>
</ul>
<p>​    性质不同的任务可以用不同规模的线程池分开处理。</p>
<p>​    CPU密集型任务应配置尽可能小的线程，如配置Ncpu+1个线程的线程池。由于IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程，如2*Ncpu。</p>
<p>​    混合型的任务，如果可以拆分，将其拆分成一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量。如果这两个任务执行时间相差太大，则没必要进行分解。可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。</p>
<p>​    优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先执行。</p>
<p>​    执行时间不同的任务可以交给不同规模的线程池来处理，或者可以使用优先级队列，让执行时间短的任务先执行。</p>
<p>​    建议使用有界队列。有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点儿，比如几千。</p>
<p>​    如果当时我们设置成无界队列，那么线程池的队列就会越来越多，有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。</p>
<h1 id="AbstractQueuedSynchronizer"><a href="#AbstractQueuedSynchronizer" class="headerlink" title="AbstractQueuedSynchronizer"></a>AbstractQueuedSynchronizer</h1><h2 id="学习AQS的必要性"><a href="#学习AQS的必要性" class="headerlink" title="学习AQS的必要性"></a>学习AQS的必要性</h2><p>​    队列同步器AbstractQueuedSynchronizer（以下简称同步器或AQS），是用来构建锁或者其他同步组件的基础框架，<strong>它使用了一个int成员变量表示同步状态</strong>（state），通过内置的FIFO队列来完成资源获取线程的排队工作。并发包的大师（Doug Lea）期望它能够成为实现大部分同步需求的基础。</p>
<h2 id="AQS使用方式和其中的设计模式"><a href="#AQS使用方式和其中的设计模式" class="headerlink" title="AQS使用方式和其中的设计模式"></a>AQS使用方式和其中的设计模式</h2><p>​    AQS的主要使用方式是继承，子类通过继承AQS并实现它的抽象方法来管理同步状态，在AQS里由一个int型的state来代表这个状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法（getState()、setState(int newState)和compareAndSetState(int expect,int update)）来进行操作，因为它们能够保证状态的改变是安全的。</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/state.png" class title="state"> 

<p>​    在实现上，子类推荐被定义为自定义同步组件的静态内部类，AQS自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。</p>
<p>​    同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器。可以这样理解二者之间的关系：</p>
<p>​    锁是面向使用者的，它定义了使用者与锁交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；</p>
<p>​    同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。锁和同步器很好地隔离了使用者和实现者所需关注的领域。</p>
<p>​    实现者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。</p>
<h3 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h3><p>​    同步器的设计基于模板方法模式。模板方法模式的意图是，定义一个操作中的算法的骨架，而将一些步骤的实现延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。我们最常见的就是Spring框架里的各种Template。 </p>
<h2 id="AQS中的方法"><a href="#AQS中的方法" class="headerlink" title="AQS中的方法"></a>AQS中的方法</h2><h3 id="模板方法"><a href="#模板方法" class="headerlink" title="模板方法"></a>模板方法</h3><p>实现自定义同步组件时，将会调用同步器提供的模板方法，</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95.png" class title="模板方法">  

<p>​    这些模板方法同步器提供的模板方法基本上分为3类：独占式获取与释放同步状态、共享式获取与释放、同步状态和查询同步队列中的等待线程情况。</p>
<h3 id="可重写的方法"><a href="#可重写的方法" class="headerlink" title="可重写的方法"></a>可重写的方法</h3><img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%8F%AF%E9%87%8D%E5%86%99%E7%9A%84%E6%96%B9%E6%B3%95.png" class title="可重写的方法">  

<h3 id="访问或修改同步状态的方法"><a href="#访问或修改同步状态的方法" class="headerlink" title="访问或修改同步状态的方法"></a>访问或修改同步状态的方法</h3><p>重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。</p>
<ul>
<li><p>getState()：获取当前同步状态。</p>
</li>
<li><p>setState(int newState)：设置当前同步状态。</p>
</li>
<li><p>compareAndSetState(int expect,int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性。 </p>
</li>
</ul>
<h2 id="CLH队列锁"><a href="#CLH队列锁" class="headerlink" title="CLH队列锁"></a>CLH队列锁</h2><p>CLH队列锁即Craig, Landin, and Hagersten (CLH) locks。</p>
<p>CLH队列锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程仅仅在本地变量上自旋，它不断轮询前驱的状态，假设发现前驱释放了锁就结束自旋。</p>
<p>当一个线程需要获取锁时：</p>
<ol>
<li><p>创建一个的QNode，将其中的locked设置为true表示需要获取锁，myPred表示对其前驱结点的引用</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CLH%E9%98%9F%E5%88%97%E9%94%811.png" class title="CLH队列锁1">   
</li>
<li><p>线程A对tail域调用getAndSet方法，使自己成为队列的尾部，同时获取一个指向其前驱结点的引用myPred</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CLH%E9%98%9F%E5%88%97%E9%94%812.png" class title="CLH队列锁2">   

<p>线程B需要获得锁，同样的流程再来一遍</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CLH%E9%98%9F%E5%88%97%E9%94%813.png" class title="CLH队列锁3">   

</li>
</ol>
<p>3.线程就在前驱结点的locked字段上旋转，直到前驱结点释放锁(前驱节点的锁值 locked == false)</p>
<p>4.当一个线程需要释放锁时，将当前结点的locked域设置为false，同时回收前驱结点</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CLH%E9%98%9F%E5%88%97%E9%94%814.png" class title="CLH队列锁4">   

<p>​    如上图所示，前驱结点释放锁，线程A的myPred所指向的前驱结点的locked字段变为false，线程A就可以获取到锁。</p>
<p>​    CLH队列锁的优点是空间复杂度低（如果有n个线程，L个锁，每个线程每次只获取一个锁，那么需要的存储空间是O（L+n），n个线程有n个myNode，L个锁有L个tail）。CLH队列锁常用在SMP体系结构下。</p>
<p>​    Java中的AQS是CLH队列锁的一种变体实现。</p>
<h1 id="深入理解并发编程和归纳总结"><a href="#深入理解并发编程和归纳总结" class="headerlink" title="深入理解并发编程和归纳总结"></a>深入理解并发编程和归纳总结</h1><h2 id="JMM基础-计算机原理"><a href="#JMM基础-计算机原理" class="headerlink" title="JMM基础-计算机原理"></a>JMM基础-计算机原理</h2><p>​    Java内存模型即Java Memory Model，简称JMM。JMM定义了Java 虚拟机(JVM)在计算机内存(RAM)中的工作方式。JVM是整个计算机虚拟模型，所以JMM是隶属于JVM的。Java1.5版本对其进行了重构，现在的Java仍沿用了Java1.5的版本。Jmm遇到的问题与现代计算机中遇到的问题是差不多的。</p>
<p>​    物理计算机中的并发问题，物理机遇到的并发问题与虚拟机中的情况有不少相似之处，物理机对并发的处理方案对于虚拟机的实现也有相当大的参考意义。</p>
<p>​    计算机在做一些我们平时的基本操作时，需要的响应时间是不一样的。</p>
<p>​    现实情况中绝大多数的运算任务都不可能只靠处理器“计算”就能完成，处理器至少要与内存交互，如读取运算数据、存储运算结果等，这个I/O操作是基本上是无法消除的（无法仅靠寄存器来完成所有运算任务）。早期计算机中cpu和内存的速度是差不多的，但在现代计算机中，<strong>cpu的指令速度远超内存的存取速度</strong>,由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.png" class title="计算机内存模型">   

<h2 id="Java内存模型（JMM）"><a href="#Java内存模型（JMM）" class="headerlink" title="Java内存模型（JMM）"></a>Java内存模型（JMM）</h2><p>​    从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个<strong>私有的本地内存（Local Memory）</strong>，本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。</p>
<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JMM1.png" class title="JMM1">    

<img src="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JMM2.png" class title="JMM2">     

<h3 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h3><p>​    可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。</p>
<p>​    由于线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量，那么对于共享变量V，它们首先是在自己的工作内存，之后再同步到主内存。可是并不会及时的刷到主存中，而是会有一定时间差。很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了 。</p>
<p>​    要解决共享对象可见性这个问题，我们可以使用volatile关键字或者是加锁。</p>
<h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>​    原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。</p>
<p>​    我们都知道CPU资源的分配都是以线程为单位的,并且是分时调用,操作系统允许某个进程执行一小段时间，例如 50 毫秒，过了 50 毫秒操作系统就会重新选择一个进程来执行（我们称为“任务切换”），这个 50 毫秒称为“时间片”。而任务的切换大多数是在时间片段结束以后。</p>
<p>​    那么线程切换为什么会带来bug呢？因为操作系统做任务切换，可以发生在任何一条CPU 指令执行完！注意，是 CPU 指令，CPU 指令，CPU 指令，而不是高级语言里的一条语句。比如count++，在java里就是一句话，但高级语言里一条语句往往需要多条 CPU 指令完成。其实count++包含了三个CPU指令！</p>
<h2 id="volatile详解"><a href="#volatile详解" class="headerlink" title="volatile详解"></a>volatile详解</h2><h3 id="volatile特性"><a href="#volatile特性" class="headerlink" title="volatile特性"></a>volatile特性</h3><p>​    可以把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步 </p>
<p>​    所以volatile变量自身具有下列特性：</p>
<ul>
<li><p>可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。</p>
</li>
<li><p>原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。</p>
</li>
</ul>
<p>​    volatile虽然能保证执行完及时把变量刷到主内存中，但对于count++这种非原子性、多指令的情况，由于线程切换，线程A刚把count=0加载到工作内存，线程B就可以开始工作了，这样就会导致线程A和B执行完的结果都是1，都写到主内存中，主内存的值还是1不是2</p>
<h3 id="volatile的实现原理"><a href="#volatile的实现原理" class="headerlink" title="volatile的实现原理"></a>volatile的实现原理</h3><p>​    通过对OpenJDK中的unsafe.cpp源码的分析，会发现被volatile关键字修饰的变量会存在一个“lock:”的前缀。</p>
<p>​    Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。</p>
<p>​    同时该指令会将当前处理器缓存行的数据直接写会到系统内存中，且这个写回内存的操作会使在其他CPU里缓存了该地址的数据无效。</p>
<h2 id="ReentrantLock的实现"><a href="#ReentrantLock的实现" class="headerlink" title="ReentrantLock的实现"></a>ReentrantLock的实现</h2><h3 id="锁的可重入"><a href="#锁的可重入" class="headerlink" title="锁的可重入"></a>锁的可重入</h3><p>重入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题。</p>
<p>1）线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。</p>
<p>2）锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。</p>
<p>​    nonfairTryAcquire方法增加了再次获取同步状态的处理逻辑：通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是获取锁的线程再次请求，则将同步状态值进行增加并返回true，表示获取同步状态成功。同步状态表示锁被一个线程重复获取的次数。</p>
<p>​    如果该锁被获取了n次，那么前(n-1)次tryRelease(int releases)方法必须返回false，而只有同步状态完全释放了，才能返回true。可以看到，该方法将同步状态是否为0作为最终释放的条件，当同步状态为0时，将占有线程设置为null，并返回true，表示释放成功。</p>
<h3 id="公平和非公平锁"><a href="#公平和非公平锁" class="headerlink" title="公平和非公平锁"></a>公平和非公平锁</h3><p>​    ReentrantLock的构造函数中，默认的无参构造函数将会把Sync对象创建为NonfairSync对象，这是一个“非公平锁”；而另一个构造函数ReentrantLock(boolean fair)传入参数为true时将会把Sync对象创建为“公平锁”FairSync。</p>
<p>​    nonfairTryAcquire(int acquires)方法，对于非公平锁，只要CAS设置同步状态成功，则表示当前线程获取了锁，而公平锁则不同。    tryAcquire方法，该方法与nonfairTryAcquire(int acquires)比较，唯一不同的位置为判断条件多了hasQueuedPredecessors()方法，即加入了同步队列中当前节点是否有前驱节点的判断，如果该方法返回true，则表示有线程比当前线程更早地请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁。</p>
<h2 id="synchronized的实现原理"><a href="#synchronized的实现原理" class="headerlink" title="synchronized的实现原理"></a>synchronized的实现原理</h2><p>​    Synchronized在JVM里的实现都是基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的MonitorEnter和MonitorExit指令来实现。</p>
<p>​    对同步块，MonitorEnter指令插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象Monitor的所有权，即尝试获得该对象的锁，而monitorExit指令则插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的MonitorExit。</p>
<p>​    对同步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来实现，相对于普通方法，其常量池中多了<strong>ACC_SYNCHRONIZED标示符</strong>。</p>
<p>​    JVM就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。</p>
<h3 id="了解各种锁"><a href="#了解各种锁" class="headerlink" title="了解各种锁"></a>了解各种锁</h3><h4 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h4><h5 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h5><p>​    自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。</p>
<p>​    但是线程自旋是需要消耗CPU的，说白了就是让CPU在做无用功，线程不能一直占用CPU自旋做无用功，所以需要设定一个自旋等待的最大时间。</p>
<p>​    如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。</p>
<h5 id="自旋锁的优缺点"><a href="#自旋锁的优缺点" class="headerlink" title="自旋锁的优缺点"></a>自旋锁的优缺点</h5><p>​    自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起操作的消耗！</p>
<p>​    但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，占着XX不XX，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cup的线程又不能获取到cpu，造成cpu的浪费。</p>
<h5 id="自旋锁时间阈值"><a href="#自旋锁时间阈值" class="headerlink" title="自旋锁时间阈值"></a>自旋锁时间阈值</h5><p>​    自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。因此自旋次数很重要</p>
<p>​    JVM对于自旋次数的选择，jdk1.5默认为10次，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。</p>
<p>​    JDK1.6中-XX:+UseSpinning开启自旋锁； JDK1.7后，去掉此参数，由jvm控制；</p>
<h3 id="锁的状态"><a href="#锁的状态" class="headerlink" title="锁的状态"></a>锁的状态</h3><p>​    一共有四种状态，<strong><em>无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态</em></strong>，它会随着竞争情况逐渐升级。锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率。</p>
<h4 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h4><p>​    引入背景：大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁，减少不必要的CAS操作。</p>
<p>​    偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，减少加锁／解锁的一些CAS操作（比如等待队列的一些CAS操作），这种情况下，就会给线程加一个偏向锁。 如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。</p>
<p>偏向锁获取过程：</p>
<p>步骤1、 访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。</p>
<p>步骤2、 如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。</p>
<p>步骤3、 如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。</p>
<p>步骤4、 如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）</p>
<p>步骤5、 执行同步代码。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/" data-id="cki5werml0007o0vb9ivfbmt4" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2020/11/30/%E6%B3%A8%E8%A7%A3%E4%B8%8E%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">注解与动态代理</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">August 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/11/30/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/">并发编程</a>
          </li>
        
          <li>
            <a href="/2020/11/30/%E6%B3%A8%E8%A7%A3%E4%B8%8E%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/">注解与动态代理</a>
          </li>
        
          <li>
            <a href="/2020/11/20/%E7%BD%91%E7%BB%9C%E6%A1%86%E6%9E%B6/">网络框架</a>
          </li>
        
          <li>
            <a href="/2020/10/27/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a>
          </li>
        
          <li>
            <a href="/2020/10/22/binder/">binder</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 xuesui<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>